# Docker Compose for go-cluster Multi-Node Deployment
#
# This example demonstrates a production-like HA setup with:
# - 3-node NATS cluster with JetStream
# - 3 go-cluster nodes participating in leader election
# - Prometheus for metrics collection
# - Grafana for visualization (optional)
#
# Usage:
#   docker compose up -d              # Start all services
#   docker compose logs -f node-1     # Watch node-1 logs
#   docker compose stop node-1        # Simulate node failure
#   docker compose ps                 # Check status
#   docker compose down -v            # Cleanup
#
# Test failover:
#   1. Start the cluster: docker compose up -d
#   2. Watch logs: docker compose logs -f node-1 node-2 node-3
#   3. Kill the leader: docker compose stop node-1
#   4. Observe automatic failover to node-2 or node-3

name: go-cluster-demo

services:
  # =============================================================================
  # NATS Cluster (3 nodes for HA)
  # =============================================================================
  
  nats-1:
    image: nats:2.10-alpine
    container_name: nats-1
    hostname: nats-1
    command: >
      -js
      -n nats-1
      -c /etc/nats/nats.conf
      --cluster_name go-cluster-nats
      --cluster nats://0.0.0.0:6222
      --routes nats://nats-2:6222,nats://nats-3:6222
    ports:
      - "4222:4222"   # Client connections
      - "8222:8222"   # HTTP monitoring
    volumes:
      - ./config/nats.conf:/etc/nats/nats.conf:ro
      - nats-1-data:/data
    networks:
      - cluster-net
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8222/healthz"]
      interval: 5s
      timeout: 3s
      retries: 3
    restart: unless-stopped

  nats-2:
    image: nats:2.10-alpine
    container_name: nats-2
    hostname: nats-2
    command: >
      -js
      -n nats-2
      -c /etc/nats/nats.conf
      --cluster_name go-cluster-nats
      --cluster nats://0.0.0.0:6222
      --routes nats://nats-1:6222,nats://nats-3:6222
    ports:
      - "4223:4222"
      - "8223:8222"
    volumes:
      - ./config/nats.conf:/etc/nats/nats.conf:ro
      - nats-2-data:/data
    networks:
      - cluster-net
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8222/healthz"]
      interval: 5s
      timeout: 3s
      retries: 3
    restart: unless-stopped

  nats-3:
    image: nats:2.10-alpine
    container_name: nats-3
    hostname: nats-3
    command: >
      -js
      -n nats-3
      -c /etc/nats/nats.conf
      --cluster_name go-cluster-nats
      --cluster nats://0.0.0.0:6222
      --routes nats://nats-1:6222,nats://nats-2:6222
    ports:
      - "4224:4222"
      - "8224:8222"
    volumes:
      - ./config/nats.conf:/etc/nats/nats.conf:ro
      - nats-3-data:/data
    networks:
      - cluster-net
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8222/healthz"]
      interval: 5s
      timeout: 3s
      retries: 3
    restart: unless-stopped

  # =============================================================================
  # go-cluster Nodes (3 nodes for HA)
  # =============================================================================

  node-1:
    build:
      context: ../..
      dockerfile: examples/docker-compose/Dockerfile
    container_name: go-cluster-node-1
    hostname: node-1
    environment:
      - NODE_ID=node-1
      - NATS_URL=nats://nats-1:4222,nats://nats-2:4222,nats://nats-3:4222
      - PLATFORM=demo-cluster
      - HEALTH_ADDR=:8080
      - METRICS_ADDR=:9090
      - LABELS_ZONE=zone-a
      - LABELS_ROLE=worker
    ports:
      - "8081:8080"   # Health endpoint
      - "9091:9090"   # Metrics endpoint
    volumes:
      - node-1-data:/data
    networks:
      - cluster-net
    depends_on:
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      nats-3:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped

  node-2:
    build:
      context: ../..
      dockerfile: examples/docker-compose/Dockerfile
    container_name: go-cluster-node-2
    hostname: node-2
    environment:
      - NODE_ID=node-2
      - NATS_URL=nats://nats-1:4222,nats://nats-2:4222,nats://nats-3:4222
      - PLATFORM=demo-cluster
      - HEALTH_ADDR=:8080
      - METRICS_ADDR=:9090
      - LABELS_ZONE=zone-b
      - LABELS_ROLE=worker
    ports:
      - "8082:8080"
      - "9092:9090"
    volumes:
      - node-2-data:/data
    networks:
      - cluster-net
    depends_on:
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      nats-3:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped

  node-3:
    build:
      context: ../..
      dockerfile: examples/docker-compose/Dockerfile
    container_name: go-cluster-node-3
    hostname: node-3
    environment:
      - NODE_ID=node-3
      - NATS_URL=nats://nats-1:4222,nats://nats-2:4222,nats://nats-3:4222
      - PLATFORM=demo-cluster
      - HEALTH_ADDR=:8080
      - METRICS_ADDR=:9090
      - LABELS_ZONE=zone-c
      - LABELS_ROLE=worker
    ports:
      - "8083:8080"
      - "9093:9090"
    volumes:
      - node-3-data:/data
    networks:
      - cluster-net
    depends_on:
      nats-1:
        condition: service_healthy
      nats-2:
        condition: service_healthy
      nats-3:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped

  # =============================================================================
  # Monitoring Stack (Optional)
  # =============================================================================

  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: prometheus
    hostname: prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - cluster-net
    depends_on:
      - node-1
      - node-2
      - node-3
    restart: unless-stopped
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:10.2.2
    container_name: grafana
    hostname: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3000:3000"
    volumes:
      - ./config/grafana/provisioning:/etc/grafana/provisioning:ro
      - grafana-data:/var/lib/grafana
    networks:
      - cluster-net
    depends_on:
      - prometheus
    restart: unless-stopped
    profiles:
      - monitoring

# =============================================================================
# Networks
# =============================================================================

networks:
  cluster-net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

# =============================================================================
# Volumes
# =============================================================================

volumes:
  nats-1-data:
  nats-2-data:
  nats-3-data:
  node-1-data:
  node-2-data:
  node-3-data:
  prometheus-data:
  grafana-data:
